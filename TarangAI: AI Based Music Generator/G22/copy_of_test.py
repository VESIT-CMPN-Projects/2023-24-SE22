# -*- coding: utf-8 -*-
"""Copy of test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fRRRRU6j197W9qeVvm1RCd7AOU3O9CG3

**L**
"""

# !pip show tensorflow

# !pip install tensorflow

# !pip show keras

# from google.colab import drive
# drive.mount('/content/dataset')

# !sudo apt install -y fluidsynth

# !pip install --upgrade pyfluidsynth

# !pip install pretty_midi
import os
import collections
import datetime
import fluidsynth
import glob
import numpy as np
import pathlib
import pandas as pd
import pretty_midi
import seaborn as sns
import tensorflow as tf

from IPython import display
from matplotlib import pyplot as plt
from typing import Optional

seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)

# Sampling rate for audio playback
_SAMPLING_RATE = 16000

# data_dir = pathlib.Path('data/maestro-v2.0.0')
# if not data_dir.exists():
#   tf.keras.utils.get_file(
#       'maestro-v2.0.0-midi.zip',
#       origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',
#       extract=True,
#       cache_dir='.', cache_subdir='data',
#   )
def get_files_in_folder(folder_path):
    files_list = []
    if os.path.exists(folder_path) and os.path.isdir(folder_path):
        files_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]
    else:
        print(f"Error: Folder '{folder_path}' does not exist or is not a directory.")
    return files_list

filenames = get_files_in_folder('C:/Users/DELL/Downloads/mididataset sad songs/mididataset sad songs')  #this is storing all the file in array
print('Number of files:', len(filenames))

sample_file = filenames[1]
print(sample_file)

pmc = pretty_midi.PrettyMIDI(sample_file)

"""the above library return the synthesized output means it will calculate all the stuff and return the data"""

def display_audio(pm: pretty_midi.PrettyMIDI, seconds=60):
  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)
  # Take a sample of the generated waveform to mitigate kernel resets
  waveform_short = waveform[:seconds*_SAMPLING_RATE]
  return display.Audio(waveform_short, rate=_SAMPLING_RATE)

display_audio(pmc)

# print('Number of instruments:', len(pmc.instruments))
instrument = pmc.instruments[0]
instrument_name = pretty_midi.program_to_instrument_name(instrument.program)
print('Instrument name:', instrument_name)

"""Imp cell"""

for i, note in enumerate(instrument.notes[:10]):
  note_name = pretty_midi.note_number_to_name(note.pitch)
  duration = note.end - note.start
  print(f'{i}: pitch={note.pitch}, note_name={note_name},'
        f' duration={duration:.4f}')

# from google.colab import auth
# auth.authenticate_user()


# from google.colab import drive
# drive.mount('/content/dataset')

def midi_to_notes(midi_file: str) -> pd.DataFrame:
  pm = pretty_midi.PrettyMIDI(midi_file)  #the main this pretty midi is doing giving all the data
  instrument = pm.instruments[0]
  notes = collections.defaultdict(list)

  # Sort the notes by start time
  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)
  prev_start = sorted_notes[0].start

  for note in sorted_notes:
    start = note.start
    end = note.end
    notes['pitch'].append(note.pitch)
    notes['start'].append(start)
    notes['end'].append(end)
    notes['step'].append(start - prev_start)
    notes['duration'].append(end - start)
    prev_start = start

  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})

"""The above function we convert the midi to notes imp

Here the raw notes is the dataset variable name
"""

raw_notes = midi_to_notes("/content/AGAR TUM SAATH HO Full VIDEO song  Tamasha  Ranbir Kapoor, Deepika Padukone  T-Series.mid")  #this sample file was declared before
raw_notes.head()

get_note_names = np.vectorize(pretty_midi.note_number_to_name)
sample_note_names = get_note_names(raw_notes['pitch'])
sample_note_names[:10]

"""plot_piano_roll function plots graph on base pitch and time in notes"""

def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):
  if count:
    title = f'First {count} notes'
  else:
    title = f'Whole track'
    count = len(notes['pitch'])
  plt.figure(figsize=(20, 4))
  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)
  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)
  plt.plot(                       # this is mathplot library
      plot_start_stop[:, :count], plot_pitch[:, :count], color="b", marker=".")
  plt.xlabel('Time [s]')
  plt.ylabel('Pitch')
  _ = plt.title(title)

# plot_piano_roll(raw_notes, count=100)   #this is print the first 100 notes

# plot_piano_roll(raw_notes)    #this will print the notes of whole song

def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):
  plt.figure(figsize=[15, 5])
  plt.subplot(1, 3, 1)
  sns.histplot(notes, x="pitch", bins=20)

  plt.subplot(1, 3, 2)
  max_step = np.percentile(notes['step'], 100 - drop_percentile)
  sns.histplot(notes, x="step", bins=np.linspace(0, max_step, 21))

  plt.subplot(1, 3, 3)
  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)
  sns.histplot(notes, x="duration", bins=np.linspace(0, max_duration, 21))

# plot_distributions(raw_notes)

"""Here we again we are converting notes to midi"""

# def notes_to_midi(
#   notes: pd.DataFrame,
#   out_file: str,
#   instrument_name: str,
#   velocity: int = 100,  # note loudness
# ) -> pretty_midi.PrettyMIDI:

#   pm = pretty_midi.PrettyMIDI()
#   instrument = pretty_midi.Instrument(
#       program=pretty_midi.instrument_name_to_program(     # again the pretty midi is converting the notes to midi
#           instrument_name))

#   prev_start = 0
#   for i, note in notes.iterrows():
#     start = float(prev_start + note['step'])
#     end = float(start + note['duration'])
#     note = pretty_midi.Note(
#         velocity=velocity,
#         pitch=int(note['pitch']),
#         start=start,
#         end=end,
#     )
#     instrument.notes.append(note)
#     prev_start = start

#   pm.instruments.append(instrument)
#   pm.write(out_file)
#   return pm

def notes_to_midi(
  notes: pd.DataFrame,
  out_file: str,
  instrument_name: str,
  velocity: int = 100,  # note loudness
) -> pretty_midi.PrettyMIDI:

  pm = pretty_midi.PrettyMIDI()
  instrument = pretty_midi.Instrument(
      program=pretty_midi.instrument_name_to_program(     # again the pretty midi is converting the notes to midi
          instrument_name))

  prev_start = 0
  for i, note in notes.iterrows():
    start = float(note['step'])
    end = float(note['duration'])
    note = pretty_midi.Note(
        velocity=velocity,
        pitch=int(note['pitch']),
        start=start,
        end=end,
    )
    instrument.notes.append(note)
    prev_start = end

  pm.instruments.append(instrument)
  pm.write(out_file)
  return pm

# example_file = 'example.midi'
# example_pm = notes_to_midi(
#     raw_notes, out_file=example_file, instrument_name=instrument_name)

# display_audio(example_pm)

"""Creating data set 5"""

num_files = 10
all_notes = []
for f in filenames[:num_files]:
  notes = midi_to_notes(f)         #notes of 5 files
  all_notes.append(notes)

all_notes = pd.concat(all_notes)

len(all_notes)

# import os
# import pandas as pd

# # Assuming filenames is a list containing the MIDI file paths in Colab content
# filenames = [os.path.join('/content', filename) for filename in os.listdir('/content') if filename.endswith('.MID') or filename.endswith('.mid')]

# num_files = 10
# all_notes = []

# for f in filenames[:num_files]:
#     print(f)
#     notes = midi_to_notes(f)
#     all_notes.append(notes)

# all_notes = pd.concat(all_notes)

n_notes = len(all_notes)
print('Number of notes parsed:', n_notes)

key_order = ['pitch', 'step', 'duration']
train_notes = np.stack([all_notes[key] for key in key_order], axis=1)

notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)  #here it is making notes dataset
notes_ds.element_spec

def create_sequences(
    dataset: tf.data.Dataset,
    seq_length: int,
    vocab_size = 128,
) -> tf.data.Dataset:
  """Returns TF Dataset of sequence and label examples."""
  seq_length = seq_length+1

  # Take 1 extra for the labels
  windows = dataset.window(seq_length, shift=1, stride=1,
                              drop_remainder=True)

  # `flat_map` flattens the" dataset of datasets" into a dataset of tensors
  flatten = lambda x: x.batch(seq_length, drop_remainder=True)
  sequences = windows.flat_map(flatten)

  # Normalize note pitch
  def scale_pitch(x):
    x = x/[vocab_size,3.0,4.0]
    return x

  # Split the labels
  def split_labels(sequences):
    inputs = sequences[:-1]
    labels_dense = sequences[-1]
    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}

    return scale_pitch(inputs), labels

  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)

seq_length = 1
vocab_size = 256
seq_ds = create_sequences(notes_ds, seq_length, vocab_size)
seq_ds.element_spec

for seq, target in seq_ds.take(1):
  print('sequence shape:', seq.shape)
  print('sequence elements (first 10):', seq[0: 10])
  print()
  print('target:', target)

batch_size = 128
buffer_size = n_notes - seq_length  # the number of items in the dataset
train_ds = (seq_ds
            .shuffle(buffer_size)
            .batch(batch_size, drop_remainder=True)
            .cache()
            .prefetch(tf.data.experimental.AUTOTUNE))

train_ds.element_spec

"""A

**Model yaha hai**
"""

def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):
  mse = (y_true - y_pred) ** 2
  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)
  return tf.reduce_mean(mse + positive_pressure)

input_shape = (seq_length, 3)
learning_rate = 0.10

inputs = tf.keras.Input(input_shape)
x = tf.keras.layers.LSTM(128)(inputs)

outputs = {
  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),
  'step': tf.keras.layers.Dense(1, name='step')(x),
  'duration': tf.keras.layers.Dense(1, name='duration')(x),
}

model = tf.keras.Model(inputs, outputs)

loss = {
      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(
          from_logits=True),
      'step': mse_with_positive_pressure,
      'duration': mse_with_positive_pressure,
}

optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

model.compile(loss=loss, optimizer=optimizer)

model.summary()

# import tensorflow as tf

# input_shape = (seq_length, 3)
# learning_rate = 0.10

# inputs = tf.keras.Input(input_shape)
# x = tf.keras.layers.LSTM(128, recurrent_initializer='glorot_uniform')(inputs)

# outputs = {
#     'pitch': tf.keras.layers.Dense(128, name='pitch')(x),
#     'step': tf.keras.layers.Dense(1, name='step')(x),
#     'duration': tf.keras.layers.Dense(1, name='duration')(x),
# }

# model = tf.keras.Model(inputs, outputs)

# loss = {
#     'pitch': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
#     'step': mse_with_positive_pressure,
#     'duration': mse_with_positive_pressure,
# }

# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

# model.compile(loss=loss, optimizer=optimizer)

# model.summary()

losses = model.evaluate(train_ds, return_dict = True)
losses

model.compile(
    loss=loss,
    loss_weights={
        'pitch': 0.05,
        'step': 0.5,
        'duration':0.5,
    },
    optimizer=optimizer,
)

model.evaluate(train_ds, return_dict=True)

"""** training**"""

callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        filepath='./training_checkpoints/ckpt_{epoch}',
        save_weights_only=True),
    tf.keras.callbacks.EarlyStopping(
        monitor='loss',
        patience=5,
        verbose=1,
        restore_best_weights=True),
]

# Commented out IPython magic to ensure Python compatibility.
# %%time
# epochs = 50
# 
# history = model.fit(
#     train_ds,
#     epochs=epochs,
#     callbacks=callbacks,
# )

plt.plot(history.epoch, history.history['loss'], label='total loss')
plt.show()

model.save('/content/model21.h5')
print("Trained model saved successfully.")

# model.save('new.keras')

model.save('model21no')

# !pip show tensorflow

import tensorflow as tf
from tensorflow.keras.models import load_model

# Define the custom loss function
def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):
  mse = (y_true - y_pred) ** 2
  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)
  return tf.reduce_mean(mse + positive_pressure)

# Register the custom loss function with Keras
losses = {'mse_with_positive_pressure': mse_with_positive_pressure}

# Load the model with custom loss function
model = load_model("/content/new_model.h5", custom_objects=losses)

from tensorflow.keras.models import load_model
model=load_model("/content/new_model.h5")

def predict_next_note(
    notes: np.ndarray,
    model: tf.keras.Model,
    temperature: float = 1.0) -> tuple[int, float, float]:
  """Generates a note as a tuple of (pitch, step, duration), using a trained sequence model."""

  assert temperature > 0

  # Add batch dimension
  inputs = tf.expand_dims(notes, 0)

  predictions = model.predict(inputs)
  pitch_logits = predictions['pitch']
  step = predictions['step']
  duration = predictions['duration']
  print(pitch_logits)
  print(step)
  print(duration)

  pitch_logits /= temperature
  pitch = tf.random.categorical(pitch_logits, num_samples=1)
  pitch = tf.squeeze(pitch, axis=-1)
  duration = tf.squeeze(duration, axis=-1)
  step = tf.squeeze(step, axis=-1)

  # `step` and `duration` values should be non-negative
  step = tf.maximum(0, step)
  duration = tf.maximum(0, duration)
  print("----------------------------------------------------------------")
  print(int(pitch))
  print(float(step))
  print(float(duration))
  print("----------------------------------------------------------------")


  return int(pitch), float(step), float(duration)

temperature = 10.0
num_predictions = 120

sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)

# The initial sequence of notes; pitch is normalized similar to training

# sequences
input_notes = (
    [[80,0.12,0.36]])
print(len(input_notes))
print('///////////////////////////////////')
generated_notes_1 = []
prev_start = 0
for _ in range(num_predictions):
  pitch, step, duration = predict_next_note(input_notes, model, temperature)
  start = prev_start + step
  end = start + duration
  input_note = (pitch, step, duration)
  generated_notes_1.append((*input_note, start, end))
  input_notes = np.delete(input_notes, 0, axis=0)
  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)
  prev_start = end

generated_notes_1 = pd.DataFrame(
    generated_notes_1, columns=(*key_order, 'start', 'end'))

generated_notes_1

def notes_to_midi(
  notes: pd.DataFrame,
  out_file: str,
  instrument_name: str,
  velocity: int = 100,  # note loudness
) -> pretty_midi.PrettyMIDI:

  pm = pretty_midi.PrettyMIDI()
  instrument = pretty_midi.Instrument(
      program=pretty_midi.instrument_name_to_program(     # again the pretty midi is converting the notes to midi
          instrument_name))

  prev_start = 0
  for i, note in notes.iterrows():
    start = float(note['start'])
    end = float(note['end'])
    note = pretty_midi.Note(
        velocity=velocity,
        pitch=int(note['pitch']),
        start=start,
        end=end,
    )
    instrument.notes.append(note)
    prev_start = end

  pm.instruments.append(instrument)
  pm.write(out_file)
  return pm

out_file = 'output.mid'
out_pm1 = notes_to_midi(
    generated_notes_1, out_file=out_file, instrument_name=instrument_name)
display_audio(out_pm1)

# from google.colab import files
# files.download(out_file)

plot_piano_roll(generated_notes_1)

plot_distributions(generated_notes_1)

